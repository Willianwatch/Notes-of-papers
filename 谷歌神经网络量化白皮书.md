# 谷歌神经网络量化白皮书
## 简介
- 迫切需要一些技术来优化模型，以减少模型规模、更快的推理和降低功耗
  - 设计轻量级模型
  - 通过量化、剪枝和压缩技术减少模型的大小
- 降低任何模型复杂性的一个更简单的方法是降低权重和激活的精度要求（**模型量化**）。这种方法有许多优点：
  - 它广泛适用于一系列的模型和用例。人们不需要开发一个新的模型架构来提高速度。在许多情况下，我们可以从现有的浮点模型开始，快速量化，得到一个几乎没有精度损失的不动点量化模型，而不需要重新训练模型。多个硬件平台和库支持具有量化权重和激活功能的快速推断，因此不需要等待新的硬件开发。
  - 更小的模型占用空间：使用8位量化，人们可以将模型尺寸减少4倍，而精度损失可以忽略不计。这可以在不需要任何数据的情况下完成，因为只有权重是量化的。这也导致了模型更新的下载时间的加快。
  - 用于激活的工作内存和缓存减少：中间计算通常存储在缓存中，以便被深度网络的后期层重用，降低存储数据的精度会导致所需的工作内存减少。具有较低的精度权重和激活功能，允许更好的缓存重用。
  - 更快的计算速度：大多数处理器允许更快地处理8位数据。
  - 低功率：移动8位数据比移动32位浮点数据的效率高4倍。在许多深度体系结构中，内存访问可以主导功耗。因此，减少数据移动量可以对功耗产生显著影响。
以上所有因素都可以转化为更快的推理，由于内存访问和计算的精度降低，典型的加速速度为2-3倍。通过为低精度矢量算法优化的处理器和硬件加速器，可以进一步提高速度和功耗。

## 量化器设计
